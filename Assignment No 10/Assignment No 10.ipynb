{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d226ede1",
   "metadata": {},
   "source": [
    "1: Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb658d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: click in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fae5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\samik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f9954",
   "metadata": {},
   "source": [
    "2: Sample Training Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af816327",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "I love machine learning\n",
    "I love artificial intelligence\n",
    "Machine learning is amazing\n",
    "Artificial intelligence is the future\n",
    "I love deep learning\n",
    "Deep learning is powerful\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5ba76",
   "metadata": {},
   "source": [
    "3: Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2fde24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(corpus.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683ad40",
   "metadata": {},
   "source": [
    "4: Build Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f932879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(tokens, n=3):\n",
    "    model = defaultdict(Counter)\n",
    "    \n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        context = tuple(tokens[i:i+n-1])\n",
    "        next_word = tokens[i+n-1]\n",
    "        model[context][next_word] += 1\n",
    "        \n",
    "    return model\n",
    "\n",
    "trigram_model = build_ngram_model(tokens, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0368d",
   "metadata": {},
   "source": [
    "5: Add Laplace Smoothing & Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81bade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, context, vocab_size):\n",
    "    context = tuple(context)\n",
    "    \n",
    "    if context not in model:\n",
    "        return None\n",
    "    \n",
    "    word_counts = model[context]\n",
    "    total_count = sum(word_counts.values())\n",
    "    \n",
    "    probabilities = {}\n",
    "    \n",
    "    for word in word_counts:\n",
    "        # Laplace smoothing\n",
    "        probabilities[word] = (word_counts[word] + 1) / (total_count + vocab_size)\n",
    "    \n",
    "    return sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489b65f",
   "metadata": {},
   "source": [
    "6: Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf981bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(tokens)\n",
    "vocab_size = len(vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b20767",
   "metadata": {},
   "source": [
    "7: Auto-Complete Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b90788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(text, model, vocab_size, n=3, top_k=3):\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    if len(words) < n-1:\n",
    "        return \"Not enough words for prediction\"\n",
    "    \n",
    "    context = words[-(n-1):]\n",
    "    predictions = predict_next_word(model, context, vocab_size)\n",
    "    \n",
    "    if predictions:\n",
    "        return predictions[:top_k]\n",
    "    else:\n",
    "        return \"No prediction available\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b43704",
   "metadata": {},
   "source": [
    "8: Test the Auto-Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e2af7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i love\n",
      "Suggestions: [('machine', 0.13333333333333333), ('artificial', 0.13333333333333333), ('deep', 0.13333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"i love\"\n",
    "suggestions = autocomplete(input_text, trigram_model, vocab_size)\n",
    "\n",
    "print(\"Input:\", input_text)\n",
    "print(\"Suggestions:\", suggestions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

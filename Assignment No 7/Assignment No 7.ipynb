{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3eae4ae",
   "metadata": {},
   "source": [
    "Develop a text preprocessing and analysis application using NLTK for tokenization, POS \n",
    "tagging, and basic NLP tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfbc50",
   "metadata": {},
   "source": [
    "1. Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e0a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\samik\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2250d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fd48e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\samik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\samik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\samik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2a883",
   "metadata": {},
   "source": [
    "2. Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee4ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Natural Language Processing enables machines to understand \n",
    "and analyze human language efficiently.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a24351",
   "metadata": {},
   "source": [
    "3. Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09caabc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNatural Language Processing enables machines to understand \\nand analyze human language efficiently.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b605b76",
   "metadata": {},
   "source": [
    "4. Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc68c610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'enables',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'human',\n",
       " 'language',\n",
       " 'efficiently',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(text.lower())\n",
    "words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d39154",
   "metadata": {},
   "source": [
    "5. Remove Stopwords & Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a252494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'enables',\n",
       " 'machines',\n",
       " 'understand',\n",
       " 'analyze',\n",
       " 'human',\n",
       " 'language',\n",
       " 'efficiently']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "clean_words = [\n",
    "    word for word in words \n",
    "    if word not in stop_words and word not in string.punctuation\n",
    "]\n",
    "\n",
    "clean_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24b6c0",
   "metadata": {},
   "source": [
    "6. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ebc1d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " 'enabl',\n",
       " 'machin',\n",
       " 'understand',\n",
       " 'analyz',\n",
       " 'human',\n",
       " 'languag',\n",
       " 'effici']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in clean_words]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff12492",
   "metadata": {},
   "source": [
    "7.Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881851cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'enables',\n",
       " 'machine',\n",
       " 'understand',\n",
       " 'analyze',\n",
       " 'human',\n",
       " 'language',\n",
       " 'efficiently']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in clean_words]\n",
    "lemmatized_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73acb369",
   "metadata": {},
   "source": [
    "8. POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2284171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('enables', 'VBZ'),\n",
       " ('machine', 'NN'),\n",
       " ('understand', 'NN'),\n",
       " ('analyze', 'NN'),\n",
       " ('human', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('efficiently', 'RB')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = pos_tag(lemmatized_words)\n",
    "pos_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df99e9",
   "metadata": {},
   "source": [
    "9. Basic NLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1fd6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'language': 2,\n",
       "         'natural': 1,\n",
       "         'processing': 1,\n",
       "         'enables': 1,\n",
       "         'machine': 1,\n",
       "         'understand': 1,\n",
       "         'analyze': 1,\n",
       "         'human': 1,\n",
       "         'efficiently': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Frequency\n",
    "word_freq = Counter(lemmatized_words)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15fcffea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 2),\n",
       " ('natural', 1),\n",
       " ('processing', 1),\n",
       " ('enables', 1),\n",
       " ('machine', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most Common Words\n",
    "word_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6936e9",
   "metadata": {},
   "source": [
    "10.Complete Pipeline Function (Reusable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f77820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_pipeline(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    clean = [w for w in words if w not in stop_words and w not in string.punctuation]\n",
    "    lemmas = [lemmatizer.lemmatize(w) for w in clean]\n",
    "    tags = pos_tag(lemmas)\n",
    "    return tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec84edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nltk', 'RB'),\n",
       " ('widely', 'RB'),\n",
       " ('used', 'VBN'),\n",
       " ('text', 'NN'),\n",
       " ('preprocessing', 'VBG'),\n",
       " ('nlp', 'JJ'),\n",
       " ('task', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_pipeline(\"NLTK is widely used for text preprocessing and NLP tasks.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
